================================================================================
LINEAR TEMPORAL LOGIC FORMULA COMPLEXITY IMPACT ANALYSIS
================================================================================

Report Generated: 2025-08-08 13:44:32
Analysis Tool: LTL Optimization Performance Analyzer
Dataset: 45 benchmark instances, 1,544 formulas

EXECUTIVE SUMMARY
----------------------------------------

This report analyzes the relationship between Linear Temporal Logic (LTL)
formula complexity metrics and optimization performance in terms of processing
time and reduction effectiveness. The analysis covers 45 benchmark instances
with a total of 1,544 formulas processed.

PERFORMANCE CHARACTERISTICS
----------------------------------------

Processing Time Range:
  • Minimum: 0.000568 seconds per formula
  • Maximum: 13.616759 seconds per formula
  • Mean: 0.507738 seconds per formula
  • Standard Deviation: 2.324524 seconds

Formula Reduction Effectiveness:
  • Minimum Reduction: 0.0%
  • Maximum Reduction: 91.7%
  • Mean Reduction: 35.3%
  • Standard Deviation: 29.6%

COMPLEXITY METRICS CORRELATION ANALYSIS
----------------------------------------

The following correlation coefficients measure the linear relationship
between complexity metrics and processing time (Pearson correlation):

  • Temporal Operators  : r = +0.699 (Strong positive correlation) (significant)
  • Formula Length      : r = +0.665 (Strong positive correlation) (significant)
  • Atomic Propositions : r = +0.535 (Moderate positive correlation) (significant)
  • Nesting Depth       : r = +0.444 (Moderate positive correlation)
  • Logical Operators   : r = +0.247 (Weak positive correlation)


Note: Correlations with |r| > 0.5 are considered statistically significant
for this analysis. Strong correlations (|r| > 0.6) indicate substantial
predictive relationships between complexity metrics and performance.

BENCHMARK PERFORMANCE ANALYSIS
----------------------------------------

Top 5 Most Efficient Benchmarks (Low Complexity, Fast Processing):

  1. driving_phils.5_000      
     Processing Time: 0.000913 seconds/formula
     Complexity Score: 0.251
     Reduction Rate: 0.0%

  2. driving_phils.3_000      
     Processing Time: 0.000920 seconds/formula
     Complexity Score: 0.251
     Reduction Rate: 0.0%

  3. driving_phils.1_000      
     Processing Time: 0.000796 seconds/formula
     Complexity Score: 0.257
     Reduction Rate: 50.0%

  4. driving_phils.4_000      
     Processing Time: 0.000773 seconds/formula
     Complexity Score: 0.257
     Reduction Rate: 50.0%

  5. driving_phils.2_000      
     Processing Time: 0.000785 seconds/formula
     Complexity Score: 0.257
     Reduction Rate: 50.0%

Top 5 Most Challenging Benchmarks (High Complexity, Slow Processing):

  1. anderson.7_000           
     Processing Time: 0.000841 seconds/formula
     Complexity Score: 0.590
     Reduction Rate: 42.9%

  2. collision.4_000          
     Processing Time: 0.817608 seconds/formula
     Complexity Score: 0.723
     Reduction Rate: 7.4%

  3. brp.4_000                
     Processing Time: 0.353159 seconds/formula
     Complexity Score: 0.840
     Reduction Rate: 10.0%

  4. bridge.3_000             
     Processing Time: 7.945750 seconds/formula
     Complexity Score: 0.844
     Reduction Rate: 19.6%

  5. cyclic_scheduler.3_000   
     Processing Time: 13.616759 seconds/formula
     Complexity Score: 0.887
     Reduction Rate: 9.3%

EFFICIENCY OUTLIERS
----------------------------------------

Benchmarks performing significantly better than expected based on complexity:
(Efficiency ratio > 1.5 indicates superior performance relative to complexity)

  • bopdp.3_000              : 11860.98x efficiency ratio
  • bopdp.1_000              : 11780.48x efficiency ratio
  • bopdp.2_000              : 11751.43x efficiency ratio
  • anderson.7_000           : 9554.04x efficiency ratio
  • at.7_000                 : 7891.97x efficiency ratio

CATEGORICAL PERFORMANCE ANALYSIS
----------------------------------------

Performance by Temporal Operator Density:

  Low (≤2.5)     :
    Mean Processing Time: 0.000833 ± 0.000137 seconds
    Mean Reduction Rate: 37.1%
    Sample Size: 40 benchmarks

  High (4-6)     :
    Mean Processing Time: 0.449609 ± 0.520428 seconds
    Mean Reduction Rate: 33.4%
    Sample Size: 2 benchmarks

  Very High (>6) :
    Mean Processing Time: 7.305223 ± 6.654959 seconds
    Mean Reduction Rate: 13.0%
    Sample Size: 3 benchmarks

Performance by Formula Length:

  Short (≤50)    :
    Mean Processing Time: 0.000773 ± 0.000143 seconds
    Mean Reduction Rate: 49.3%
    Sample Size: 12 benchmarks

  Medium (50-75) :
    Mean Processing Time: 0.004539 ± 0.017215 seconds
    Mean Reduction Rate: 33.5%
    Sample Size: 22 benchmarks

  Long (75-100)  :
    Mean Processing Time: 0.001026 ± 0.000036 seconds
    Mean Reduction Rate: 52.1%
    Sample Size: 2 benchmarks

  Very Long (>100):
    Mean Processing Time: 2.526335 ± 4.897741 seconds
    Mean Reduction Rate: 17.3%
    Sample Size: 9 benchmarks

KEY FINDINGS AND INSIGHTS
----------------------------------------

Primary Performance Predictors:

  1. Temporal Operators emerges as the strongest predictor of processing time
     (correlation coefficient: r = 0.699)

  2. Temporal operator density significantly impacts algorithm performance.
     Each additional temporal operator contributes measurably to processing time.

  3. Formula length demonstrates moderate correlation with processing time,
     indicating scalability challenges with longer logical expressions.

Algorithmic Performance Assessment:

  • Overall Reduction Effectiveness: Moderate
    (Mean reduction rate: 35.3%)

  • Computational Scalability: Limited
    (Maximum processing time: 13.617 seconds per formula)

RECOMMENDATIONS FOR ALGORITHM OPTIMIZATION
----------------------------------------

1. High-Priority Optimization Target: Temporal Operators
   Strong correlation (r = 0.699) indicates significant
   performance gains possible through targeted optimization of this metric.

2. Temporal Operator Preprocessing:
   Consider implementing specialized handling for formulas with >6 temporal
   operators to mitigate performance degradation in complex cases.

3. Scalability Enhancement:
   Current maximum processing time suggests room for algorithmic
   improvements in worst-case scenarios.

4. Benchmark-Specific Considerations:
   Focus optimization efforts on the identified challenging benchmarks
   while maintaining performance on efficient cases.

CONCLUSION
----------------------------------------

The LTL optimization algorithm demonstrates moderate performance
characteristics with a mean reduction rate of 35.3% across
45 benchmark instances. The analysis reveals that temporal operators
serves as the primary complexity factor affecting processing time.

The algorithm exhibits limited scalability, with processing times
ranging from 0.000568 to 13.616759 seconds per formula.
This performance profile indicates the approach is well-suited for practical
applications while highlighting specific areas for targeted optimization.

================================================================================